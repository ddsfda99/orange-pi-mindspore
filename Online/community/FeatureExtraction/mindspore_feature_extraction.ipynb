{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829b6f5e-b8d1-4af4-b1b5-2e876c0a95bb",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "220577e8-2fed-4b27-817f-f110f528c3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] DEVICE(8007,e7ffc1dc5020,python):2025-08-15-18:25:46.861.807 [mindspore/ccsrc/utils/dlopen_macro.h:165] DlsymAscend] Dynamically load symbol aclprofGetSupportedFeaturesV2 failed, result = /usr/local/Ascend/ascend-toolkit/latest/lib64/libmsprofiler.so: undefined symbol: aclprofGetSupportedFeaturesV2\n",
      "[WARNING] DEVICE(8007,e7ffc1dc5020,python):2025-08-15-18:25:46.861.936 [mindspore/ccsrc/utils/dlopen_macro.h:165] DlsymAscend] Dynamically load symbol aclrtEventGetTimestamp failed, result = /usr/local/Ascend/ascend-toolkit/latest/lib64/libascendcl.so: undefined symbol: aclrtEventGetTimestamp\n",
      "/usr/local/miniconda3/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/miniconda3/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/usr/local/miniconda3/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/miniconda3/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import sys, platform, os, time\n",
    "import mindspore as ms\n",
    "from mindspore import context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5904ef4-0842-49ba-895c-4828e9b30a83",
   "metadata": {},
   "source": [
    "依赖检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de4fa28-a2e6-4f26-8cec-ca1897e6cb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(8007:255085655117856,MainProcess):2025-08-15-18:25:53.460.708 [mindspore/context.py:1402] For 'context.set_context', the parameter 'ascend_config' will be deprecated and removed in a future version. Please use the api mindspore.device_context.ascend.op_precision.precision_mode(),\n",
      "                                                       mindspore.device_context.ascend.op_precision.op_precision_mode(),\n",
      "                                                       mindspore.device_context.ascend.op_precision.matmul_allow_hf32(),\n",
      "                                                       mindspore.device_context.ascend.op_precision.conv_allow_hf32(),\n",
      "                                                       mindspore.device_context.ascend.op_tuning.op_compile() instead.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 2.137 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindnlp==? (要求 0.4.1)\n",
      "numpy 已安装\n",
      "缺失 scikit_learn，开始安装……\n",
      ">>> /usr/local/miniconda3/bin/python -m pip install scikit_learn\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit_learn in /usr/local/miniconda3/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from scikit_learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from scikit_learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/miniconda3/lib/python3.9/site-packages (from scikit_learn) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from scikit_learn) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "import importlib, subprocess, sys\n",
    "\n",
    "def ensure(pkg, ver=None):\n",
    "    try:\n",
    "        m = importlib.import_module(pkg)\n",
    "        if ver:\n",
    "            print(f\"{pkg}=={getattr(m,'__version__','?')} (要求 {ver})\")\n",
    "        else:\n",
    "            print(f\"{pkg} 已安装\")\n",
    "    except Exception as e:\n",
    "        print(f\"缺失 {pkg}，开始安装……\")\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", pkg + (f\"=={ver}\" if ver else \"\")]\n",
    "        print(\">>>\", \" \".join(cmd))\n",
    "        subprocess.check_call(cmd)\n",
    "\n",
    "ensure(\"mindnlp\", \"0.4.1\")\n",
    "ensure(\"numpy\")\n",
    "ensure(\"scikit_learn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f026f47-fba9-41bd-b14c-7c5acb86f186",
   "metadata": {},
   "source": [
    "从 Hugging Face 官方源加载 BGE small zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a123d16a-8292-452a-9791-eb5ba2baa16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: BAAI/bge-small-zh-v1.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 512, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 512)\n",
       "    (token_type_embeddings): Embedding(2, 512)\n",
       "    (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-3): 4 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear (512 -> 512)\n",
       "            (key): Linear (512 -> 512)\n",
       "            (value): Linear (512 -> 512)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear (512 -> 512)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear (512 -> 2048)\n",
       "          (intermediate_act_fn): GELU(approximate='none')\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear (2048 -> 512)\n",
       "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear (512 -> 512)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindnlp.transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "MODEL_ID = \"BAAI/bge-small-zh-v1.5\"  \n",
    "print(\"Loading:\", MODEL_ID)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)   \n",
    "model = AutoModel.from_pretrained(MODEL_ID)\n",
    "model.set_train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d32b0-9e99-4d1c-bd91-8792add0ecd6",
   "metadata": {},
   "source": [
    "文本特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15892e7f-301d-4ad0-ab76-7d1f5b7f4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.ops as ops\n",
    "\n",
    "def encode_texts(texts, max_len=256, batch_size=16):\n",
    "    all_vecs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"ms\")\n",
    "        out = model(**enc)\n",
    "        mask = enc[\"attention_mask\"].astype(ms.float32).expand_dims(-1) \n",
    "        summed = ops.sum(out.last_hidden_state * mask, dim=1, keepdim=False)  \n",
    "        counts = ops.clip_by_value(ops.sum(mask, dim=1, keepdim=False), 1.0, 1e9)\n",
    "        mean_pooled = summed / counts  \n",
    "        all_vecs.append(mean_pooled.asnumpy())\n",
    "    return np.vstack(all_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b9ad60-dbb6-4ef2-bc8b-508c23042ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量形状: (3, 512)\n",
      "句子 1：生活就像一杯茶，慢慢品味才能感受其中的香醇。\n",
      "前5维示例: [ 0.286835 -0.009755  0.012051 -0.090807 -0.450408]\n",
      "\n",
      "句子 2：科学技术是第一生产力。\n",
      "前5维示例: [ 0.071481  0.325284  0.453272 -0.222929 -0.320808]\n",
      "\n",
      "句子 3：读书破万卷，下笔如有神。\n",
      "前5维示例: [-0.186404  0.551733  0.001602 -0.302225 -0.129176]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"生活就像一杯茶，慢慢品味才能感受其中的香醇。\",\n",
    "    \"科学技术是第一生产力。\",\n",
    "    \"读书破万卷，下笔如有神。\"\n",
    "]\n",
    "embeddings = encode_texts(texts)\n",
    "print(\"向量形状:\", embeddings.shape)  \n",
    "for idx, sent in enumerate(texts):\n",
    "    print(f\"句子 {idx+1}：{sent}\")\n",
    "    print(\"前5维示例:\", np.round(embeddings[idx][:5], 6))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
